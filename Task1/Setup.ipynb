{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import timm  # For Vision Transformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdul\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Models\n",
    "\n",
    "#CNN Model:\n",
    "\n",
    "cnn_model = torchvision.models.resnet50(pretrained=True)\n",
    "cnn_model.fc = nn.Linear(cnn_model.fc.in_features, 10)  # STL-10 has 10 classes\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "\n",
    "#ViT Model:\n",
    "vit_model = timm.create_model(\"vit_small_patch16_224\", pretrained=True, num_classes=10)\n",
    "vit_model = vit_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base Dataset\n",
    "\n",
    "cnn_transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),  # upscale CIFAR-10 (32x32) to 96x96 so both models work fine\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))  # ImageNet normalization\n",
    "])\n",
    "\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # upscale CIFAR-10 (32x32) to 96x96 so both models work fine\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))  # ImageNet normalization\n",
    "])\n",
    "\n",
    "cnn_train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=cnn_transform)\n",
    "cnn_test_dataset  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=cnn_transform)\n",
    "\n",
    "cnn_train_loader = DataLoader(cnn_train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "cnn_test_loader  = DataLoader(cnn_test_dataset,  batch_size=64, shuffle=False, pin_memory=True)\n",
    "\n",
    "vit_train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=vit_transform)\n",
    "vit_test_dataset  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=vit_transform)\n",
    "\n",
    "vit_train_loader = DataLoader(vit_train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "vit_test_loader  = DataLoader(vit_test_dataset,  batch_size=64, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images shape: torch.Size([64, 3, 96, 96])\n",
      "Batch labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(cnn_train_loader))\n",
    "print(\"Batch images shape:\", X.shape)\n",
    "print(\"Batch labels shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model functions\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    return (y_true == y_pred).sum().item() / len(y_true) * 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=1e-4)\n",
    "optimizer_vit = optim.AdamW(vit_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_step(model, data_loader, loss_fn, optimizer, accuracy_fn, device=device):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Create a progress bar for the DataLoader\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
    "\n",
    "    for X, y in progress_bar:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # Loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Accuracy\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the progress bar with current loss and accuracy\n",
    "        progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)))\n",
    "\n",
    "    return train_loss / len(data_loader), train_acc / len(data_loader)\n",
    "\n",
    "def test_step(model, data_loader, loss_fn, accuracy_fn, device=device):\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # Create a progress bar for the DataLoader\n",
    "        progress_bar = tqdm(data_loader, desc=\"Testing\")\n",
    "        for X, y in progress_bar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Loss + accuracy\n",
    "            loss = loss_fn(y_pred, y).item()\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "            # Update the progress bar with current loss and accuracy\n",
    "            progress_bar.set_postfix(loss=loss, accuracy=accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)))\n",
    "\n",
    "    return test_loss / len(data_loader), test_acc / len(data_loader)\n",
    "\n",
    "# def train_step(model, data_loader, loss_fn, optimizer, accuracy_fn, device=device):\n",
    "#     model.train()\n",
    "#     train_loss, train_acc = 0, 0\n",
    "\n",
    "#     for X, y in data_loader:\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         y_pred = model(X)\n",
    "\n",
    "#         # Loss\n",
    "#         loss = loss_fn(y_pred, y)\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#         # Accuracy\n",
    "#         train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "#         # Backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)))\n",
    "\n",
    "#     return train_loss / len(data_loader), train_acc / len(data_loader)\n",
    "\n",
    "\n",
    "# def test_step(model, data_loader, loss_fn, accuracy_fn, device=device):\n",
    "#     model.eval()\n",
    "#     test_loss, test_acc = 0, 0\n",
    "\n",
    "#     with torch.inference_mode():\n",
    "#         for X, y in data_loader:\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             y_pred = model(X)\n",
    "\n",
    "#             # Loss + accuracy\n",
    "#             test_loss += loss_fn(y_pred, y).item()\n",
    "#             test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "#     return test_loss / len(data_loader), test_acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [01:45<00:00,  7.44it/s, accuracy=100, loss=0.0529] \n",
      "Testing: 100%|██████████| 157/157 [00:09<00:00, 15.99it/s, accuracy=93.8, loss=0.407] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNN] Train Loss: 0.3184, Train Acc: 89.42%\n",
      "[CNN] Test  Loss: 0.1943, Test  Acc: 93.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [07:21<00:00,  1.77it/s, accuracy=100, loss=0.0161] \n",
      "Testing: 100%|██████████| 157/157 [00:35<00:00,  4.44it/s, accuracy=93.8, loss=0.135] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ViT] Train Loss: 0.1439, Train Acc: 95.33%\n",
      "[ViT] Test  Loss: 0.1033, Test  Acc: 96.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Simple test\n",
    "\n",
    "cnn_train_loss, cnn_train_acc = train_step(cnn_model, cnn_train_loader, loss_fn, optimizer_cnn, accuracy_fn)\n",
    "cnn_test_loss, cnn_test_acc   = test_step(cnn_model, cnn_test_loader, loss_fn, accuracy_fn)\n",
    "\n",
    "print(f\"[CNN] Train Loss: {cnn_train_loss:.4f}, Train Acc: {cnn_train_acc:.2f}%\")\n",
    "print(f\"[CNN] Test  Loss: {cnn_test_loss:.4f}, Test  Acc: {cnn_test_acc:.2f}%\")\n",
    "\n",
    "vit_train_loss, vit_train_acc = train_step(vit_model, vit_train_loader, loss_fn, optimizer_vit, accuracy_fn)\n",
    "vit_test_loss, vit_test_acc   = test_step(vit_model, vit_test_loader, loss_fn, accuracy_fn)\n",
    "\n",
    "print(f\"[ViT] Train Loss: {vit_train_loss:.4f}, Train Acc: {vit_train_acc:.2f}%\")\n",
    "print(f\"[ViT] Test  Loss: {vit_test_loss:.4f}, Test  Acc: {vit_test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:10<00:00, 15.30it/s, accuracy=93.8, loss=0.407] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNN] Test  Loss: 0.1943, Test  Acc: 93.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:32<00:00,  4.84it/s, accuracy=93.8, loss=0.135] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ViT] Test  Loss: 0.1033, Test  Acc: 96.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc   = test_step(cnn_model, cnn_test_loader, loss_fn, accuracy_fn)\n",
    "print(f\"[CNN] Test  Loss: {test_loss:.4f}, Test  Acc: {test_acc:.2f}%\")\n",
    "\n",
    "test_loss, test_acc   = test_step(vit_model, vit_test_loader, loss_fn, accuracy_fn)\n",
    "print(f\"[ViT] Test  Loss: {test_loss:.4f}, Test  Acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models...\n",
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Define file paths for saving\n",
    "cnn_path = \"resnet50_cifar10_new.pth\"\n",
    "vit_path = \"vit_small_cifar10_new.pth\"\n",
    "\n",
    "print(\"Saving models...\")\n",
    "\n",
    "# Save the CNN model's state_dict\n",
    "torch.save(cnn_model.state_dict(), cnn_path)\n",
    "\n",
    "# Save the ViT model's state_dict\n",
    "torch.save(vit_model.state_dict(), vit_path)\n",
    "\n",
    "print(\"Models saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
